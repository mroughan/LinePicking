\documentclass{article}
% This text is inserted in the beginning of all
% LaTex and Tex files I create.
%
% File created: Thu Apr  1 2010
% File name:    paper.tex
% Path:         /home/mroughan/Reports/Networking/Topology/Waxman/
%
% Matthew Roughan
% matthew.roughan@adelaide.edu.au
%
\usepackage{fancyhdr}
\usepackage{epsf}
\usepackage{subfig}
\usepackage{latexsym}
\usepackage{dsfont}
\usepackage{url}
\usepackage{times}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{ifthen}
\usepackage{verbatim}
\usepackage{cite}

\setlength{\headheight}{10mm}
\setlength{\headsep}{10mm}
\setlength{\topmargin}{0cm}
\setlength{\textwidth}{175mm}
\setlength{\textheight}{225mm}
\setlength{\oddsidemargin}{-10mm}
\lefthyphenmin=2
\righthyphenmin=3

\renewcommand{\baselinestretch}{1.0}
\renewcommand{\textfraction}{0.1}


\def\RR{\mathds{R}}
\def\CC{\mathds{C}}

\newcommand{\titlestr}{Known Results for the Line-Picking Problem}
\rhead[]{{\small \titlestr}}
\lhead[{\small }]{}
\cfoot{}
\rfoot[]{{\rm\thepage}}
\lfoot[{\rm\thepage}]{}
\renewcommand{\footrulewidth}{0.4pt}
\pagestyle{fancy}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[theorem]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{Def}{Definition}[section]


\begin{document}
\title{\titlestr}
\author{Matthew Roughan \;\;\; Eric Parsonage \;\;\; Jonathon Tuke \\
 School of Mathematical Sciences \\
 University of Adelaide \\
 \url{ <{matthew.roughan,eric.parsonage,}@adelaide.edu.au> } }
\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

The {\em line-picking} problem is a standard problem in stochastic
geometry, where we pick lines at random from some region. The typical
questions one asks are what will then mean line length be? What will
the Probability Density Function (PDF) be?

This brief note describes the current list of known PDFs, and where
they were derived, as well as the current set of code to calculate
these. 

The code is written in C with minimal external dependencies, and with
suitable wrapper functions for Matlab and R, to allow it to be run on
a wide variety of systems.



Motivation: examples of uses
\begin{itemize}

\item Modelling a PNNI hierarchical routing protocol for ATM packet
  telecommunication networks~\cite{Rosenberg200499} (length of lines
  in rectangles);

\item 

\end{itemize}

\section{Problem Definition}

Start with a space $\Omega$, from which we can draw points $x$ at
random. Typical examples include a rectangle in $R^2$, or a hyperball
in $R^n$.

Draw two IID (Independently, Identically Distributed) points from the
space, and draw a line between the points. The line could refer to the
natural geodesic on the space, or something more complicated such as
a geodesic in a higher dimensional Euclidean space in which $\Omega$
is embedded. For instance, we might consider simple straight lines
between points chosen in a rectangle, or straight lines in $R^n$
between points chosen on the surface of a sphere, or geodesics on the
surface of the same sphere.

Another way to frame this is to assume we have a distance metic
$d(\cdot, \cdot)$ on the space $\Omega$. The typical distance metric
used in these problems is the Euclidean distance, but others are
possible.

So a {\em line-picking problem} consists of 3 components:
\begin{itemize}

\item $\Omega$ (typically a subset of $R^n$)

\item The measure $\mu$ on $\Omega$ describing the choice of points
  (typically uniform)

\item The space in which we draw lines (geodesics) and its related
  distance metric.

\end{itemize}
so we describe these problems by the triple: $(\Omega, \mu, d)$. Given
that the typical case of $\mu$ is uniform, and of $d$ is Euclidean, we
often ommit these from the problem statement.

EXAMPLE FIGURES: square, surface of sphere, manhattan distance



Bertrand's Paradox of 1889, ``Does a random chord on a circle has
length exceeding the length of a side of an inscribed equilateral
triangle?''
% http://www.sciencedirect.com/science/article/pii/S0167637703000725



\section{Region Transforms}
\label{sec:scaling}

Many of the standard problems use a uniform point distribution and
Euclidean distances on some convex region of $R^n$. In these cases,
there is are easy scaling and trasnlation laws that means once we know
the distribution for some size region, we can compute it for any size.

Translation is trivial. Given the uniform distribution of point,
translation has no affect on the line-length distribution.

Scaling is almost as simple: if the region $\Omega$ is scaled in all
dimensions by $L$, then the problem is identical under a scaling of
the distance metric by $L$. We can therefore scale the density
functions as follows
\begin{equation}
 g_L(t) = \frac{1}{L} g_1\left(\frac{t}{L} \right). 
\end{equation}

Non-uniform scaling is not so simple as we shall see in the results
below.


\section{Known Results}
\label{sec:known}

The first result we present is that for the rectangle: given in
\cite[Theorem 2.4.4]{mathai_geom} and \cite[Theorem
2]{b.ghosh51:_random_rect}
\begin{equation}
  g^{\rm rect}_{a,b}(t) = \frac{4 t}{a^2 b^2} \phi_{a,b}(t),
  \label{eqn:rectangle}   
\end{equation}
where
\begin{equation}
  \phi_{a,b}(t) = \left\{
    \begin{array}{ll}
      \frac{ab \pi}{2} - (a+b) t + \frac{t^2}{2}, 
         & \mbox{ for } t \leq a, \\
      a b \sin^{-1} (a/t) - \frac{a^2}{2} - b t + b\sqrt{t^2 - a^2},
         & \mbox{ for } a \leq t \leq b, \\
      a b \left[ \sin^{-1} (a/t) - \sin^{-1} \sqrt{1 - \frac{b^2}{t^2}} \right]
        - \frac{a^2 + b^2 + t^2}{2} 
        + a\sqrt{t^2 - b^2}+ b\sqrt{t^2 - a^2},
         & \mbox{ for } b \leq t \leq \sqrt{a^2 + b^2}, \\
      0,
         & \mbox{ otherwise}, \\
    \end{array} \right. 
\end{equation}
where the rectangle has sides of length $a \leq
b$. Figure~\ref{fig:rect_density} shows these for various cases,
chosen such that $\sqrt{a^2 + b^2} = 1$ to allow comparison. We label
these rectangles by their aspect ratio $a: b$.

This is a rather complicated expression, but is easily evaluated
numerically.  Naldi \cite{m.naldi05:_connec_of_waxman_graph}
approximated this expression with a $\beta$ function, though given the
requirements to numerically evaluate that function there hardly seems
any advantage, though we shall see later that this would have been
completely appropriate if the region have been a circle.

There are two obvious special cases of the above -- the line, and the
square -- both of which have been addressed separately (e.g., see
\cite{philip:_probab_distr_distan_between_two,weisstein:_squar_line_picking}),
but which also result from limits of the above formula. The
probability density function of distances between two (uniformly)
randomly chosen points on the unit square is given in
\cite{weisstein:_squar_line_picking}, as
\begin{equation}
  \label{eq:square_line}
  g^{\rm square}(t) = \left\{ \begin{array}{ll}
      2t (t^2-4t+\pi), & \mbox{ for } 0 \leq t \leq 1, \\
      2t \left[4 \sqrt{t^2-1} - (t^2+2-\pi) - 4 \tan^{-1} \left(\sqrt{t^2-1} \right)\right], 
               & \mbox{ for } 1 \leq t \leq \sqrt{2} . \\ 
    \end{array} \right.
\end{equation}
% http://mathworld.wolfram.com/SquareLinePicking.html

The probability density function of distances between two (uniformly)
randomly chosen points on the unit line is given in
\cite{weisstein:_line_line_picking,b.ghosh51:_random_rect}, as
\begin{equation}
  \label{eq:line_line}
  g^{\rm line}(t) = 2(1-t),
\end{equation}
or for a line of length $L$ as
\begin{equation}
  \label{eq:line_lineL}
  g^{\rm line}_L(t) = \frac{2}{L} \left( 1-\frac{t}{L} \right).
\end{equation}

The results have also been extended into 3D, with the probability
density function of distances between two (uniformly) randomly chosen
points in the unit cube is given in
\cite{mathai99:_distan,weisstein:_cube_line_picking}, by a yet more
complicated, but again easily evaluated formula. Likewise the formula
have been calculated for a box (with sides $a,b$ and
$c$)~\cite{philip:_probab_distr_distan_between_two} and 4- and
5-Cubes~\cite{philip:_probab_distr_distan_between_two_4d}. Other
results are also known, for instance the distribution when the points
are chosen on the sides of the square (but lines are drawn across it)
or faces of a cube!\cite{mathai99:_distan}, and the distribution of
distances between points chosen in two different
rectangles~\cite{b.ghosh51:_random_rect}.

\begin{figure}[tbp]
  \begin{center}
    \subfloat[\label{fig:rect_density}Density distribution of rectangles, each chosen with a
      different aspect ratio $a/b$, but fixed diagonal distance
      $\sqrt{a^2 + b^2} = 1$.]{\includegraphics[width=0.33\columnwidth]{../Matlab/Plots/LinePicking_test_rect.eps}}
    \subfloat[\label{fig:b_balls}Density distribution of $n$-D balls.]{\includegraphics[width=0.33\columnwidth]{../Matlab/Plots/LinePicking_test_balls.eps}}
    \subfloat[\label{fig:various} Various densities distributions for
    shapes with area fixed to 1.]{\includegraphics[width=0.33\columnwidth]{../Matlab/Plots/LinePicking_test_fix_area.eps}}
    \caption{Example distance densities.}
  \end{center} 
\vspace{-4mm}
\end{figure}


The other obvious region on which to solve the line-picking problem is
the ball in $n$-dimensions~\cite{tu00:_circle_line} (equations
(27-31)). For a $n$-dimensional ball of radius $R$,
\begin{equation}
 g^{nD-{\rm ball}}_R(t) = n \frac{t^{n-1}}{R^n} I_x\left( 
  \frac{1}{2} (n+1), \frac{1}{2}
                      \right),
\end{equation}
where
\begin{equation}
 x = 1 - \frac{t^2}{4 R^2}, 
\end{equation}
and $I_x(p,q)$ is a {\em regularized beta function}
\begin{equation}
   I_x(p,q) = \frac{ B(x; p,q)}{B(p,q)},
\end{equation}
where $B(x; p,q)$ is an incomplete beta function, and $B(p,q)$ is a
beta function, i.e., 
\begin{eqnarray}
  B(p,q)    & = & \int_0^1 t^{p-1} (1 - t)^{q-1} \, dt, \\
  B(x; p,q) & = & \int_0^x t^{p-1} (1 - t)^{q-1} \, dt.
\end{eqnarray}
The first few of these are \cite{tu00:_circle_line} ($P_2$ in (5) and
(17), $P_3$ in (9) and (19), $P_4$ in (18) and $P_5$ in (20), general
even form in (15), general odd form in (16)):
\begin{eqnarray}
  \label{eq:ball_line_picking}
  g^{1D-{\rm ball}}_R(t) & = & \frac{1}{R} - \frac{t}{2 R}   \label{eq:line_line_picking}, \\
  g^{2D-{\rm ball}}_R(t) & = & \frac{4 t}{\pi R^2} \cos^{-1} \left( \frac{t}{2R} \right)
               - \frac{2 t^2}{\pi R^3} \sqrt{1 - \frac{t^2}{4 R^2} } \label{eq:2dball_line_picking} , \\
          & = & \frac{2 t}{R^2} 
               - \frac{2 t^2}{\pi R^3} \sqrt{1 - \frac{t^2}{4 R^2} }
               - \frac{4 t}{\pi R^2} \sin^{-1} \left( \frac{t}{2R} \right) \label{eq:2dball_line_picking2} ,  \\
  g^{3D-{\rm ball}}_R(t) & = & \frac{3 t^2}{R^3} - \frac{9 t^3}{4 R^4} + \frac{3 t^5}{16 R^6}   \label{eq:sphere_line_picking}  , \\
  g^{4D-{\rm ball}}_R(t) & = &  \frac{8 t^3}{\pi R^4} \cos^{-1} \left( \frac{t}{2R} \right) 
              - \frac{8 t^4}{3 \pi R^5} \left( 1 - \frac{t^2}{4 R^2} \right)^{3/2}
               - \frac{4 t^4}{\pi R^5} \sqrt{1 - \frac{t^2}{4 R^2} } \\
  g^{5D-{\rm ball}}_R(t) & = & \frac{5 t^4}{R^5} - \frac{75 t^6}{16 R^6} + \frac{25 t^7}{32 R^8} - \frac{15 t^9}{256 R^{10}} .
  \label{eq:ball_line_picking-end}
\end{eqnarray}
Tu and Fischbach \cite{tu00:_circle_line} also extend these results to
cases with non-uniform point distributions.
 
Figure~\ref{fig:b_balls} shows a comparison of line picking on
balls of various dimensions, and Figure~\ref{fig:various} shows a
comparison of the 2D and 3D balls to the square and cube. We can see
that as long as the areas (volumes) are matched, they appear quite
similar, respectively, though the rectangle varies considerably more.
% plot is similar to http://mathworld.wolfram.com/BallLinePicking.html




\subsection{Moments}

Ghosh \cite{b.ghosh51:_random_rect} gives the first four moments of
the line-length distribution for the rectangle.
\begin{eqnarray}
  \label{eq:rect_moments} 
  \alpha_1 & = & \frac{1}{6} \left[ 
                        \frac{b^2}{a} \cosh^{-1}\left( M/b \right) +
                        \frac{a^2}{b} \cosh^{-1}\left( M/a \right) 
                 \right]
                  + \frac{1}{15} \left[ \frac{a^3}{b^2} + \frac{b^3}{a^2} \right]
                  - \frac{M}{15} \left[ \frac{a^2}{b^2} + \frac{b^2}{a^2} -3 \right],
\\
  \alpha_2 & = & \frac{1}{6} M^2, \\
  \alpha_3 & = & \frac{1}{20} \left[ 
                        \frac{b^4}{a} \cosh^{-1}\left( M/b \right) +
                        \frac{a^4}{b} \cosh^{-1}\left( M/a \right) 
                 \right]
                  + \frac{2}{105} \left[ \frac{a^5}{b^2} + \frac{b^5}{a^2} \right]
                  - \frac{2M}{105} \left[ \frac{a^4}{b^2} + \frac{b^4}{a^2}\right]
                        - \frac{5}{84} M^3, 
\\
  \alpha_4 & = & \frac{1}{15} a^4 + \frac{1}{18} a^2 b^2 + \frac{1}{15} b^4,
\end{eqnarray}
where $M = \sqrt{a^2 + b^2}$, from which we can derive the special
cases of the square and line (though these can also be derived
directly). Obvious central moments such as mean, and variance, etc.,
can be derived from these, though forumlas will be
complex. Rosenberg~\cite{Rosenberg200499} derives a similar result,
but under different assumptions of the random selection of lines (he
assumes we first choose a random angle, then choose the line.

The mean for the cube, known as the {\em Robbins constant}, is given
in \cite{robbins78:_constant,weisstein:_cube_line_picking} as
\begin{equation}
   \label{eq:cube_mean}
 \mu^{\rm cube} = \frac{1}{105} \left[ 
                             4 + 17 \sqrt{2}- 6 \sqrt{3}  +
                             21 \ln(1+\sqrt{2}) + 
                             42 \ln(2+\sqrt{3}) - 7 \pi
                      \right]
	=	0.66170...
\end{equation}
but a closed form for the variance does not appear (only even moments
are reported). Even more complicated results appear for 4- and 5-Cubes in
5-Cubes~\cite{philip:_probab_distr_distan_between_two_4d}:
\begin{eqnarray}
 \mu^{\rm 4-cube} & = & 0.7776656535 ...    \label{eq:4-cube}, \\
 \mu^{\rm 4-cube} & = & 0.8785309152 ...     \label{eq:5-cube}.
\end{eqnarray}

The means for the $n$-dimensional ball (with radius 1) are given in
\cite{weisstein:_ball_line_picking} as
\begin{eqnarray}
  \label{eq:ball-ndim-mean}
  \mu^{1D-{\rm ball}} & = & \frac{2}{3}, \\
  \mu^{2D-{\rm ball}} & = & \frac{128}{45 \pi},\\
  \mu^{3D-{\rm ball}} & = & \frac{36}{35}, \\
  \mu^{4D-{\rm ball}} & = & \frac{16384}{4725 \pi}.
\end{eqnarray}
The more general form for higher order moments is given in
\cite{tu00:_circle_line} (equation (138-141)) as
\begin{eqnarray}
  \label{eq:ball-ndim-moments}
  \alpha_m^{nD-{\rm ball}} & = &
     \frac{n 2^{m+n}}{m+n} \frac{B\left(\frac{n+1}{2}, \frac{n+m+1}{2}  \right)}{B\left(\frac{n+1}{2}, \frac{1}{2} \right)} R^m, \\
       & = & \left( \frac{n}{n+m} \right)^2 
                 \frac{\Gamma\left( n+m+1 \right) \Gamma\left( n/2 \right) }
                      {\Gamma\left( (n+m)/2 \right) \Gamma\left( n+1 + m/2 \right) } R^m.  
\end{eqnarray}
for and $n$-dimensional ball of radius $R$.



\subsection{CDF}


Cumulative distribution functions are also known ...

Can be calculated by integration, but ...


\subsubsection{Hyperball}

As before
\begin{equation}
 g^{nD-{\rm ball}}_R(t) = n \frac{t^{n-1}}{R^n} I_x\left( 
  \frac{1}{2} (n+1), \frac{1}{2}
                      \right),
\end{equation}
where
\begin{equation}
 x = 1 - \frac{t^2}{4 R^2}, 
\end{equation}
and $I_x(p,q)$ is a {\em regularized beta function}
\begin{equation}
   I_x(p,q) = \frac{ B(x; p,q)}{B(p,q)},
\end{equation}
where $B(x; p,q)$ is an incomplete beta function, and $B(p,q)$ is a
beta function, i.e., 
\begin{eqnarray}
  B(p,q)    & = & \int_0^1 t^{p-1} (1 - t)^{q-1} \, dt, \\
  B(x; p,q) & = & \int_0^x t^{p-1} (1 - t)^{q-1} \, dt.
\end{eqnarray}

So we need to calculate terms like
\begin{eqnarray}
  \label{eq:int_incomp_beta}
  \int_0^t \tau^{n-1}  B(\tau; p,q) \, d\tau
       & = & \int_0^t \tau^{n-1}  \int_0^\tau s^{p-1} (1 - s)^{q-1} \, ds \, d\tau \nonumber \\
       & = & \int_0^t \int_0^\tau \tau^{n-1}  s^{p-1} (1 - s)^{q-1} \, ds \, d\tau \nonumber \\
       & = & \int_0^t \int_s^t \tau^{n-1}  s^{p-1} (1 - s)^{q-1} \, d\tau  \, ds \nonumber \\
       & = & \int_0^t  s^{p-1} (1 - s)^{q-1} \int_s^t \tau^{n-1} \, d\tau  \, ds \nonumber \\
       & = & \frac{1}{n} \int_0^t  s^{p-1} (1 - s)^{q-1} \left[ \tau^{n} \right]_s^t  \, ds \nonumber \\
       & = & \frac{t^n}{n} \int_0^t  s^{p-1} (1 - s)^{q-1} \, ds -
             \frac{1}{n} \int_0^t  s^{n+p-1} (1 - s)^{q-1} \, ds \nonumber \\
       & = & \frac{t^n}{n} B(t; p,q) - \frac{1}{n} B(t; p+n,q).
\end{eqnarray}
Now we need adapt this to the above case, where we calculate
$g^{nD-{\rm ball}}_R(t)$ ...

% also see http://mathworld.wolfram.com/IncompleteBetaFunction.html

\section{New Results}

ERIC todo


 
\section{Approximations}

For some problems, it may be interesting to understand the behaviour
of these distributions for small $t$. 

\subsection{Examples}

\subsubsection{Line}
For the line \eqref{eq:line_line} we need no approximation:
\begin{equation}
  g^{\rm line}_L(t) = \frac{2}{L} - \frac{2}{L^2} t.
\end{equation}

\subsubsection{Rectangle (and square)}
For the rectangle (and square) we need only restrict our attention to
the case $t<a$ (the smaller side length), to get a simple polynomial
expression: 
\begin{eqnarray}
  g^{\rm rect}_{a,b}(t) & = & 
           \frac{4 t}{a^2 b^2}  
         \left[ \frac{ab \pi}{2} - (a+b) t + \frac{t^2}{2} \right],
          \nonumber \\
                         & = & \frac{2 \pi}{A} t 
                              - \frac{2 P}{A^2} t^2
                              + \frac{2}{A^2} t^3,
\end{eqnarray}
where $A = ab$ is the area of the rectangle, and $P = a+b$ is the perimeter.

The affect of changing the scale must be obvious, in that we know area
scales quadratically, and perimeter linearly with the size of the
region, so simple dimensional analysis suggests a form such as that
above must occur, but it is perhaps suprising that it is so clean. 

\subsubsection{Cube (and box)}
For the cube~\cite{weisstein:_cube_line_picking}, for small $t$,
\begin{eqnarray}
  g^{\rm cube}_{1}(t) & = &  -t^2 \left[ (t-8)t^2 + \pi (6 t - 4) \right], \nonumber \\
                    & = & 4 \pi t^2 - 6 \pi t^3 + 8 t^4 - t^5.
\end{eqnarray}
For the box~\cite{philip:_probab_distr_distan_between_two} with $t < a
\leq b \leq c$, we first see the distribution  of $u=t^2$ (using $g(t)
= 2 t h(t^2)$, 
\begin{eqnarray}
  h^{\rm box}_{a,b,c}(u) & = &
  \frac{1}{6 a^2 b^2 c^2} \left[
    - 6 \pi b c u + 8 b u^{3/2}
    +12 \pi a b c \sqrt u - 6 \pi a(b + c)u + 8(a + c) u^{3/2} - 3 u^2
    \right], \nonumber \\
  g^{\rm box}_{a,b,c}(t)  & = &
  \frac{t }{3 a^2 b^2 c^2} \left[
    - 6 \pi b c t^2 + 8 b t^{3}
    +12 \pi a b c t - 6 \pi a(b + c)t^2 + 8(a + c) t^{3} - 3 t^4
    \right], \nonumber \\
 & = & \frac{4 \pi}{V} t^2
       + \frac{\pi }{3 V^2} \left[ -6 b c - 6 a (b+c) \right] t^3
       + \frac{1}{3 V^2} \left[ 8 b + 8 (a+c) \right] t^4
       + \frac{1}{3 V^2} \left[ - 3 \right] t^5, \nonumber \\
 & = & \frac{4 \pi}{V} t^2
       - \frac{2 \pi }{ V^2} \left[ a b + bc + a c \right] t^3
       + \frac{8}{3 V^2} \left[ a + b + c \right] t^4
       - \frac{1}{V^2} t^5,  \nonumber \\
 & = & \frac{4 \pi}{V} t^2
       - \frac{\pi S}{ V^2} t^3
       + \frac{2 P}{3 V^2}  t^4
       - \frac{1}{V^2} t^5, 
\end{eqnarray}
for volume $V = a b c$, surface area $S = 2(a b + bc + a c)$ and edge
perimeter $P = 4(a + b + c)$>


\subsubsection{Hyperball}

For the $n$-dimensional hyperball, simple approximations are available
by use of Taylor series. Ignoring the 1D case (which is the same as
the line), we see the 2D disk
from~\cite{tu00:_circle_line,weisstein:_circle_line_picking}: 
\[
   g^{2D-{\rm ball}}_R(t) 
     =  \frac{4 t}{\pi R^2} \cos^{-1} \left( \frac{t}{2R} \right) 
               - \frac{2 t^2}{\pi R^3} \sqrt{1 - \frac{t^2}{4 R^2} }          
\]
and we use
\begin{eqnarray*}
  \cos^{-1}(x)  & = & \frac{1}{2} \pi - x - \frac{1}{6} x^{3} + \cdots \\
  \sqrt{1 - x^2} & = & 1 - \frac{x^2}{2} - \frac{x^4}{8}  + \cdots.
\end{eqnarray*}
% http://www.wolframalpha.com/input/?i=Taylor+series+of+%288%2F%28pi*R%29%29*%28x*arccos%28x%29+-+x^2*sqrt%281-x^2%29+%29
% http://www.wolframalpha.com/input/?i=Taylor+series+of+%288%2F%28pi*R%29%29*%28%28t%2F%282*R%29*arccos%28t%2F%282*R%29%29+-+%28t%2F%282*R%29%29^2*sqrt%281-%28t%2F%282*R%29%29^2%29+%29
to derive
\begin{eqnarray}
  g^{2D-{\rm ball}}_R(t) 
         & = & \frac{4 t}{\pi R^2} \cos^{-1} \left( \frac{t}{2R} \right) 
               - \frac{2 t^2}{\pi R^3} \sqrt{1 - \frac{t^2}{4 R^2} }
               \nonumber \\
         & = & \frac{4 t}{\pi R^2} \left( \frac{1}{2} \pi - \frac{t}{2R} \right)
                   -  \frac{2 t^2}{\pi R^3} + O(t^4)  \nonumber \\
         & = &  \frac{2 t}{R^2} -  \frac{4 t^2}{\pi R^3}  + O(t^4) \nonumber \\
         & = &  \frac{2 \pi}{A} t -  \frac{2 P}{A^2} t^2 + O(t^4) 
\end{eqnarray}
where once again $A=\pi R^2$ and $P = 2 \pi R$ are area and perimeter,
respectively. We note that this is very similar to the formula
obtained for the square for small $t$. The first two terms are, in
fact, identical.

For the 3D ball we already have the expression as a polynomial:
\begin{eqnarray}
  g^{3D-{\rm ball}}_R(t) 
        & = & \frac{3 t^2}{R^3} - \frac{9 t^3}{4 R^4} + \frac{3 t^5}{16 R^6}  \nonumber , \\
        & = & \frac{4 \pi}{V} t^2 - \frac{\pi S}{V^2} t^3 + \frac{3}{16 R^6} t^5,
\end{eqnarray}
where again $V=4 \pi R^3/3$ and $S = 4 \pi R^2$ are the volume and
surface area. Interestingly, these are identical to those terms for
the cube, and even the forth order term is the same if we say that the
sphere has zero edges.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5


The more general expression for the $n$-D ball can be derived by
noting that for a $n$-dimensional ball of radius $R$,
\begin{equation}
 g^{nD-{\rm ball}}_R(t) = n \frac{t^{n-1}}{R^n} I_x\left( 
  \frac{1}{2} (n+1), \frac{1}{2}
                      \right),
\end{equation}
rememeber $x = 1 - t^2/4R^2$, $a=(n+1)/2$, and $b=1/2$, and from
\cite[26.5.4]{Abramowitz_and_Stegun}
\begin{eqnarray}
  \label{eq:Ix}
  I_x(a,b) 
 & = & 1 - I_{1-x}(b,a)
                    \nonumber \\
 & = & 1 - \frac{(1-x)^b x^a}{b B(b,a)}  \left\{ 
               1 +
               \sum_{i=0}^{\infty} \frac{B(b+1,i+1)}{B(a+b,i+1)} (1-x)^{i+1}
           \right\} 
               \nonumber \\
 & = & 1 - \frac{2 (t/2R) (1 - t^2/4R^2)^a}{B(b,a)}  \left\{ 
               1 +
               \sum_{i=0}^{\infty} \frac{B(b+1,i+1)}{B(a+b,i+1)} (t/2R)^{2(i+1)}
           \right\} 
               \nonumber \\
 & \simeq & 1 - \frac{t/R}{B(b,a)} 
               + \frac{a t^3/4R^3 }{B(b,a)} 
               - \frac{2 (t/2R)}{B(b,a)} \frac{B(b+1,1)}{B(a+b,1)} (t/2R)^{2}
               \nonumber \\
 & \simeq & 1 - \frac{t/R}{B(1/2,(n+1)/2)} 
               + \frac{1}{4 B(1/2,(n+1)/2)} 
                   \left[ \frac{n+1}{2}
                          -\frac{B(3/2,1)}{B(n/2+1,1)} \right] (t/R)^{3}.
\end{eqnarray}
The Gamma function satisfies\cite[6.1.12]{Abramowitz_and_Stegun}
\begin{eqnarray}
  \label{eq:gamma}
  \Gamma(1/2) & = & \pi^{1/2}, \\
  \Gamma(3/2) & = & \frac{1}{2} \pi^{1/2}, \\
  \Gamma(k+1) & = & k!, \\
  \Gamma(k+1/2) & = & \frac{(2k)! \pi^{1/2}}{2^{2k} k!},
\end{eqnarray}
% last one comes from Wiki, but could be derived simply from A&S
so we can derive
\begin{eqnarray}
  \label{eq:beta_specified_vals}
  B(1/2,(n+1)/2) & = & \frac{\Gamma(1/2) \Gamma((n+1)/2)}{\Gamma(n/2 + 1)} \nonumber \\
  & = & \left\{ \begin{array}{ll}
      \displaystyle \frac{\pi^{1/2} \Gamma(k)}{\Gamma(k+1/2)} & n \mbox{ odd, i.e., } n=2k-1,\\
      \displaystyle \frac{\pi^{1/2} \Gamma(k+ 1/2)}{\Gamma(k + 1)} & n \mbox{ even, i.e., } n=2k.\\
    \end{array} \right. \nonumber \\
  & = & \left\{ \begin{array}{ll}
      \displaystyle \frac{\pi^{1/2} 2^{2k} k! (k-1)!}{(2k)! \pi^{1/2}} & n \mbox{ odd, i.e., } n=2k-1,\\
      \displaystyle \frac{\pi^{1/2} (2k)! \pi^{1/2}}{2^{2k} k! k!} & n \mbox{ even, i.e., } n=2k.\\
    \end{array} \right. \nonumber \\
  & = & \left\{ \begin{array}{ll}
      \displaystyle \frac{2^{2k} k! (k-1)!}{(2k)! } & n \mbox{ odd, i.e., } n=2k-1,\\
      \displaystyle \frac{\pi (2k)!}{2^{2k} k! k!} & n \mbox{ even, i.e., } n=2k.\\
    \end{array} \right.
\end{eqnarray}
Thus the asymptotic form of these distributions for $t
\rightarrow 0$, i.e., 
\begin{equation}
  \label{eq:asympt_line_picking}
  g^{nD-{\rm ball}}_R(t) = n \frac{t^{n-1}}{R^n} + 
    n \frac{t^{n}}{R^{n+1}} 
   \left\{ \begin{array}{ll}
      \displaystyle 
           \frac{(2k)! }{2^{2k} k! (k-1)!} & \mbox{ for } n=2k-1,\\
      \displaystyle 
           \frac{2^{2k} k! k!}{\pi (2k)!} & \mbox{ for } n=2k.\\
    \end{array} \right\}
 +  O(t^{n+1}).
\end{equation}
For example: when $n=1,2,3$ and $4$:
\begin{eqnarray}
  \label{eq:ex_g(t)}
g^{1D-{\rm ball}}_R(t)
 & \simeq &                        
  n \frac{t^{n-1}}{R^n} - 
    n \frac{t^{n}}{R^{n+1}} 
   \left\{  \frac{(2k)! }{2^{2k} k! (k-1)!}  \right\},
                 \;\;\; \mbox{ where $n$ is odd, and } k=1,  \nonumber \\
 & \simeq &                          % (k=1, n odd)
  \frac{1}{R} - 
    \frac{1}{2} \frac{t}{R^{2}}. 
                 \\
g^{2D-{\rm ball}}_R(t)
 & \simeq &                          % (k=1, n even)
  n \frac{t^{n-1}}{R^n} - 
    n \frac{t^{n}}{R^{n+1}} 
   \left\{ \frac{2^{2k} k! k!}{\pi (2k)!}  \right\},
                 \;\;\; \mbox{ where $n$ is even, and } k=1,  \nonumber \\
 & \simeq &                          % (k=1, n even)
  2 \frac{t^{1}}{R^2} - 
    \frac{4}{\pi} \frac{t^{2}}{R^{3}} .
                  \\
g^{3D-{\rm ball}}_R(t)
 & \simeq &                          % (k=2, n odd)
  n \frac{t^{n-1}}{R^n} - 
    n \frac{t^{n}}{R^{n+1}} 
   \left\{ \frac{(2k)! }{2^{2k} k! (k-1)!}  \right\},
                 \;\;\; \mbox{ where $n$ is odd, and } k=2,  \nonumber \\
 & \simeq &                          % (k=2, n odd)
  \frac{3 t^{2}}{R^3} - 
     \frac{9}{4} \frac{t^{3}}{R^{4}} .
   \\ 
g^{4D-{\rm ball}}_R(t)
 & \simeq &                          % (k=2, n even)
  n \frac{t^{n-1}}{R^n} -  
    n \frac{t^{n}}{R^{n+1}} 
   \left\{ \frac{2^{2k} k! k!}{\pi (2k)!} \right\},
                 \;\;\; \mbox{ where $n$ is even, and } k=2, \nonumber \\
 & \simeq &                          % (k=2, n even)
  \frac{4 t^{3}}{R^4} -  
    \frac{2^5}{3\pi} \frac{t^{4}}{R^{5}} .
\end{eqnarray}
which obviously agree with the previous formula. We can also calculate
the third term in the expansion, which in the case of the 3D ball
(where the density is completely given by three terms) gives the
previous formula.


The generalized volume and surface are of the $n$-D hyperball are
\begin{eqnarray}
 V_n(R) & = & C_n R^n,
  \label{eq:gen_vol} \\
 S_{n}(R) & = & \frac{dV_n}{dR} = n C_n R^{n-1}.
  \label{eq:gen_surf}
\end{eqnarray}
where
\begin{equation}
  \label{eq:cn}
   C_n = \frac{ \pi^{n/2} }{\Gamma(n/2 + 1)},
\end{equation}
so we can write
\begin{eqnarray}
  g^{nD-{\rm ball}}_R(t)
 & \simeq  & 
      \frac{n C_n}{V_n} t^{n-1}
    -  \frac{C_n S_n}{B(1/2,(n+1)/2) V_n^2} t^{n} \nonumber  \\
 & \simeq  & 
      \frac{n C_n}{V_n} t^{n-1}
    -  \frac{ \pi^{n/2} }{\Gamma(n/2 + 1)} 
       \frac{\Gamma(n/2 + 1)}{\Gamma(1/2) \Gamma((n+1)/2)}
        \frac{S_n}{ V_n^2} t^{n} \nonumber  \\
 & \simeq  & 
      \frac{n  \pi^{n/2}}{\Gamma(n/2 + 1) V_n} t^{n-1}
    -  \frac{ \pi^{(n-1)/2} }{\Gamma((n+1)/2)}
        \frac{S_n}{ V_n^2} t^{n} .
\end{eqnarray}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5

\subsection{General pattern}

It seems as if there is a general pattern here.  That makes a good
deal of sense because for small $t$, the boundaries have little
affect. Hence, we would expect the shape of the region to only affect
the (small) line lengths through macro-properties such as the area and
perimeter.

\subsubsection{2D case}

Formally, consider a convex region in 2D, for $t$ small, we might
first assume that a random point is unlikely to be within distance $t$
of the boundary of the region, and so the probability density
function, to first order, is simply the probability that the second
point lies on the circle around this of radius $t$.
\begin{equation}
  g(t) \sim \frac{2 \pi}{A} t, 
\end{equation}

We can obtain a more accurate approximation by again assuming $t$ is
small, so that we can approximate the boundary by a straight line. In
this case, imagine the initial point was chosen (at random) to lie
with distance $t/2$ of the boundary. We can see that we over-estimate
the possible second points that lie at distance $t$. We can correct by
subtracting the number of such points that would actuall lie outside
the region.

Formally, in 2D, consider the first point lies at distance $\ell<t$
from the boundary, then there will be an arc of the circle of radius
$t$ that lies outside the circle (see
Figure~\ref{fig:perimeter}). Then the length of the arc in question
will be
\begin{equation}
  \label{eq:arc_len}
  s = 2 \theta = 2 \cos^{-1} (\ell / t).
\end{equation}
We then have to integrate over the possible distances $\ell$, i.e., 
\begin{eqnarray}
  \label{eq:correction_2nd_order}
   h(t) & = & \int_0^t 2 \cos^{-1} (\ell / t)  \, d\ell \nonumber \\
        & = &  - 2 t \int_{\pi/2}^0 \theta  \sin \theta \, d\theta  \nonumber \\
        & = &  2 t \int^{\pi/2}_0 \theta  \sin \theta \, d\theta  \nonumber \\
        & = &  2 t \left\{ \left[ -\theta  \cos \theta \right]^{\pi/2}_0 + 
                      \int^{\pi/2}_0  \cos \theta \, d\theta
                   \right\}  \nonumber \\
        & = &  2 t \left[ \sin \theta \right]^{\pi/2}_0  \nonumber \\
        & = &  2 t,
\end{eqnarray}
using the substitution $\theta = \cos^{-1} (\ell / t)$, or $\ell = t
\cos(\theta)$, so that $d \ell = - t \sin \theta$, and we integate by
parts. This must be multiplied by the probability that the first point
lies in the boundary region --- the area of the boundary divided by the
total boundary, i.e., $t P/A$, and divided by $A$ again to get the
probability that the second point would lie on the arc, if there were
no boundary, so the corrected form of $g(t)$ in 2D is
\begin{equation}
  g(t) \sim  \frac{2 \pi}{A} t - \frac{2 P}{A} t^2,
\end{equation}
which again matches the results for the rectangle and disk.

\begin{figure}[tbp]
  \begin{center}
    \includegraphics[width=0.33\columnwidth]{Figs/perimeter.eps}
    \caption{.}
    \label{fig:perimeter}
  \end{center} 
\vspace{-4mm}
\end{figure}

The next order correction would then build in the fact that the border
is not straight, e.g., in the case of a disk it is round, and in the
case of the square it has corners. However, as this term is very
dependent on shape and not general characteristics we won't calculate
it here.




\subsubsection{3D case}

Likewise for a region of 3D Euclidean space, we look at the
probability that the point lies on the surface of a sphere of radius
$t$, i.e.,
\begin{equation}
  g(t) \sim \frac{4 \pi}{V} t^2, 
\end{equation}
We can naturally generalize to $n$-D Euclidean spaces, by noting that
the generalized surface are of the $n$-D hyperball is
\begin{equation}
  \label{eq:surface_hyperball}
  S_{n} = \frac{dV_n}{dR} = n C_n R^{n-1}.
\end{equation}
where $V_n$ is its volume, and $C_n$ is defined in \eqref{eqn:cn}, so
the first order term of any expansion (for small $t$) of the density
function will take the form
\begin{equation}
  g(t) \sim \frac{n C_n}{V} t^{n-1}, 
\end{equation}
where $V$ is the $n$-D volume of the region of interest.

However, calculating the integral for the next term (correcting for
the perimeter would be tiresome, and in any case will be derived below.

\subsubsection{Higher dimensions}

We can go through exactly the same process in higher dimensions, to
obtain the same types of approximations, but computing the integrals
is somewhat redundant as we can see the correct forms of
approximatiosn directly from the hyperball distribution. Intuitively,
in high dimensions, the points are spread ``more thinly'' in the sense
that their density on $n$-dimensional volumes will be lower, and
hence, the distances between points will be larger. In particular the
chance of very short lines decreases, and we see this in the fact that
the first non-zero term in the Taylor series above has order $n-1$ for
the $n$-dimensional problem.

By the previous argument, we know that the result for the ball should
extend to arbitrary shapes, where $S_n$ is the general form of the
surface area, and $V_n$ the arbitrary form for the volume, so we could
for instance estimate the formula for small $t$ for a 4-rectangle with
sizes $a,b,c$ and $d$ as
\begin{eqnarray}
  g^{4D-{\rm rectangle}}_{a,b,c,d}(t)
 & \simeq  & 
      \frac{n C_n}{V_n} t^{n-1}
    -  \frac{ \pi^{(n-1)/2} }{\Gamma((n+1)/2)}
        \frac{S_n}{ V_n^2} t^{n} \nonumber \\
 & \simeq  & 
      \frac{2 \pi^{2}}{ a b c d} t^{3}
      -  \frac{8 \pi(abc + a b d + a c d + b c d)}{ 3 (a b c d)^2} t^{4}.
\end{eqnarray}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5

\subsection{Non-Euclidean Problems}

We can extend some of this insight into other problems, for instance,
the {\em circle line picking} problem, where pairs of points are
chosen on a circle, but the lines cross the circle. Here, the
probability distribution for line length (with a unit circle) is
\cite{weisstein:_circle_line_picking}
% http://mathworld.wolfram.com/CircleLinePicking.html
\begin{equation}
  \label{eq:circle_line_picking}
  g(t) = \frac{1}{\pi} \left(    
           1 - \frac{s^2}{4}
               \right)^{-1/2} 
       \simeq \frac{1}{\pi} \left( 1 - \frac{s^2}{4} + \cdots \right) 
\end{equation}
whereas in {\em sphere line
  picking}~\cite{weisstein:_sphere_line_picking}, there distribution
takes the form
\begin{equation}
  \label{eq:sphere_line_picking_approx}
  g(t) = \frac{1}{2} t.
\end{equation}
Clearly in this type of case, the dimension of the space is not the
critical factor, because the space on which the points are chosen is
embedded in a larger space from which lines are chosen, and the
geometry of the relationship is important.


INCIDENTALLY -- limit n -> infty for balls, has almost fixed distances
between nodes, so it approaches ER graph




\section{Numerical Computation by Simulation}
\label{sec:numerical}

It may be possible that one wishes to compute distributions, on
irregular regions, for which there is no closed form solution.
Numerically it is straight-forward to calculate the function
$g(t)$. There are two obvious approaches:
\begin{itemize}

\item Numerical computation of a $n$-dimensional integral over
  $\Omega$, or

\item Simulation of the problem, and estimation of the density from
  simulated results. 

\end{itemize}
The two approaches have different advantages and disadvantages. The
former approach has no stochastic component, and so errors are
predictable and regular. 

The later approach allows complex, potentially non-convex,
non-uniform, problems to be solved as long as they can be
simulated. Given the stochastic nature of the latter, it may help to
say a little more:

The general process is as follows:
\begin{enumerate}

\item Simulate a set of $2N$ points in the region of interest, and
  calculate the distances between successive pairs. The region may be
  irregular, or even non-convex; decisions may be made about some
  lines being inadmissable (because, for instance, they are exterior
  to the region for a non-convex region), or distances may be
  non-Euclidean, or the point distribution can be non-uniform. All
  that is needed is a set of output distances $\{ t_i \}_{i=1}^{N}$.

\item The density could then be approximate through binning, or a
  kernal smoothing technique, but in fact, we don't need direct access
  to the density as the estimator uses the Laplace transform.

\end{enumerate}

We have tested the above approach, running it 30 times (with different
seeds), in Matlab for various values of $N$. The results are shown in
Figure~\ref{fig:simulated_laplace}. The first plot shows estimates of
the mean relative absolute error of the estimated Laplace transforms
over the range $S \in [0, 50]$. We can see from the fitted straight
line, that the errors decrease as $1/\sqrt{N}$, dropping to around 1\%
at around $N=100,000$.


....





The second plot shows the computation times\footnote{Both algorithms
  were implemented in Matlab, the exact method using Matlab's {\tt
    quadqk} function. } relative to the computation times for the
``exact'' method\footnote{Note that both techniques are in some
  respect numerical, because even when we have a closed form solution
  for the density, we still typically need to numerically integrate
  this to obtain the Laplace transform, but we shall refer to this
  solution as ``exact'' for the sake of clarity in the following
  results, and because in the following we perform numerical
  integration with error tolerances of $10^{-6}$, which means the
  errors in this approach are significantly smaller than those of the
  simulation-based approach, at least for the ranges of $N$ tested
  here.}  We can immediately notice that computation times are roughly
linear in $N$, as one might expect. that around the range $N=100,000$,
the simulation approach is competitive with the exact approach.

The simulation-based approach is not as accurate as the exact
numerical approach, however, it accuracy should be sufficient for most
estimation problems, without increasing the computational workload
unduly.
make


\section{Programs}
\label{sec:program}

\subsection{A Rough Guide}

The code is arranged to be usable as
\begin{enumerate}

\item Directly, as a command-line function;

\item By linking into a larger set of code;

\item Called through a {\tt Matlab} MEX wrapper; or 

\item Called through a {\tt R} wrapper function.

\end{enumerate}
It is designed to be as independent of external libraries as possible,
needing only the C standard libraries. So compilation should be
straight forward on the majority of machines.

Ideally, typing {\tt make} in the top level directory should make all
of the targets, however, {\tt R} users may find it easier to install
using standard {\tt R} installation procedures (but not that these
won't necessarily construct the other components, need for instance
for Matlab).

The makefiles in the subdirectories are named {\tt gMakefile} to avoid
conflicts with the way {\tt R} interprets them, so if you wish to
remake a specific subdirectory, enter the directory and type: 
\verb|make -f gMakefile|.

There are a large number of functions defined in the code, for each of
the cases discussed above, however, there are a small set of functions
that you may need to be aware of, that allow one to call all of the
others through a simple, uniform interface.

....


\subsection{Numerical Issues}

Most of the computations in the code involve simple calculations, with
no obvious numerical issues (other than the obvious fact that floating
point arithmetic is being used).

The computations on the $n$-D ball, however, require calculation of
the incomplete beta function. We have provided a separate library to
perform this computation, but users may find they can obtain more
accurate results using third party library functions. 

...

Estimates of errors ...


\subsection{Tests}

The tools come with a set of tests to compare performance on your
system with ours, and ensure everything is working ...





\section{Correlations}

Correlations between distances \cite{bartlett64}

(0) correlation between a pair 1/10

(i) $n$ nodes, then $N = n (n-1)/2$ pairs of nodes, and so this many pairs of distances

(ii) the $N (N-1) /2 = n (n-1) (n (n-1) -1)/8 = $ possible pairs of
correlations

(iii) but only $n(n-1)(n-2)/2$ of the correlations are positive,
because they share a node so we get average correlation between all
pairs
 \[ \frac{1}{10} \frac{n(n-1)(n-2)/2}{n (n-1) (n (n-1) -1)/8} =
    \frac{2}{5} \frac{(n-2)}{(n (n-1) -1)}
   \simeq 
   \frac{2}{5n}
\]
for large $n$

Empirical measurement (see triples.m)
\[ r = 0.114865 \pm 0.000037\]
 
 
\section{Conclusion and Future Work}




\setlength{\parskip}{1mm}
\bibliographystyle{ieeetr}
\bibliography{queueing_theory,books,ip_traffic,time_series,reliability,tcp,ospf,lrd,worms,internet,routing,bgp,topology,network,traffic_engineering,algorithms,optimization,history,graph}
% \bibliography{LinePicking}

\end{document}


