\documentclass{article}
% This text is inserted in the beginning of all
% LaTex and Tex files I create.
%
% File created: Thu Apr  1 2010
% File name:    paper.tex
% Path:         /home/mroughan/Reports/Networking/Topology/Waxman/
%
% Matthew Roughan
% matthew.roughan@adelaide.edu.au
%
\usepackage{fancyhdr}
\usepackage{epsf}
\usepackage{subfig}
\usepackage{latexsym}
\usepackage{dsfont}
\usepackage{url}
\usepackage{times}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{ifthen}
\usepackage{verbatim}
\usepackage{cite}
\usepackage{amsfonts}
\usepackage{amssymb}

\setlength{\headheight}{10mm}
\setlength{\headsep}{10mm}
\setlength{\topmargin}{0cm}
\setlength{\textwidth}{175mm}
\setlength{\textheight}{225mm}
\setlength{\oddsidemargin}{-10mm}
\lefthyphenmin=2
\righthyphenmin=3

\renewcommand{\baselinestretch}{1.0}
\renewcommand{\textfraction}{0.1}


% \def\RR{\mathds{R}}
% \def\CC{\mathds{C}}
\def\R{\mathbb{R}}
\def\C{\mathbb{C}}
\def\Z{\mathbb{Z}}
\def\x{{\mathbf x}}
\def\y{{\mathbf y}}

\newcommand{\titlestr}{The Line-Picking Problem}
\rhead[]{{\small \titlestr}}
\lhead[{\small }]{}
\cfoot{}
\rfoot[]{{\rm\thepage}}
\lfoot[{\rm\thepage}]{}
\renewcommand{\footrulewidth}{0.4pt}
\pagestyle{fancy}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[theorem]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{Def}{Definition}[section]

\renewcommand\arraystretch{2.0} 
% \newcommand{\full}[1]{#1}
\newcommand{\full}[1]{}

\begin{document}
\title{\titlestr}
\author{Matthew Roughan \;\;\; Eric Parsonage \;\;\; Jonathan Tuke \\
 School of Mathematical Sciences \\
 University of Adelaide \\
 \url{ <{matthew.roughan,eric.parsonage,}@adelaide.edu.au> } }
\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

The {\em line-picking} problem is a standard problem in stochastic
geometry, where we pick lines at random from some region. The typical
questions one asks are what will then mean line length be? What will
the Probability Density Function (PDF) be?

This brief note describes the current list of known PDFs, and where
they were derived, as well as the current set of code to calculate
these. 

The code is written in C with minimal external dependencies, and with
suitable wrapper functions for Matlab and R, to allow it to be run on
a wide variety of systems.



Motivation: examples of uses
\begin{itemize}

\item Modelling a PNNI hierarchical routing protocol for ATM packet
  telecommunication networks~\cite{Rosenberg200499} (length of lines
  in rectangles);

\item 

\end{itemize}

Apart from a systematic survey of the line-picking problem, we have
made several contributions in this paper:
\begin{itemize}

\item For many line-picking problems, there have been works that
  determined the Probability Density Function (PDF), or Cumulative
  Density Function (CDF), or just mean and/or variance. It should be
  clear that give either the PDF or CDF the other quantities are all
  obtainable numerically, however, we primarily focus here on
  closed-form solutions, and we have provided such for many of the
  currently absent cases, e.g., the CDF for the rectangle line-picking
  problem. 

\item We have extended the circle and sphere line-picking problems to
  the $n$-sphere.

\item We have extended the line-picking problem onto addition regions,
  in particular the cylinder, ...

\item We have extended the line-picking problem to consider different
  notions of distance: for example, the Manhattanor the $L_{\infty}$
  distance on the rectangle and n-cube

\item We have extended the line-picking problem to geodesics on
  certain surfaces, notable the cylinder and $n$-sphere.

\end{itemize}



\section{Problem Definition}

Although, commonly called the ``line-picking'' problem, the problem is
more often motivated in practical problems (such as those described
above), by the problem of finding the distance between two random
points. 

This is a much better way to describe the problem. It avoids
Bertrand's paradox, where (at least) three methods of choosing a chord
of a circle at random leads to confusion and a ``paradox''.
% http://www.sciencedirect.com/science/article/pii/S0167637703000725
% http://en.wikipedia.org/wiki/Bertrand_paradox_%28probability%29
So here we shall focus on lines determined by two IID end-points, but
we shall generalize the problem substantially to motivate by the
practical problems discussed above.

We define a {\em line-picking problem} to consists of 3 components:
\begin{itemize}

\item Some space $\Omega$ (typically a subset of $R^n$), on which we
  draw independent pairs of random points.

\item The measure $\mu$ on $\Omega$ giving the probability of drawing
  points from given segments of $\Omega$. The most common measure, by
  far, is the uniform measure, resulting in a generalized Poisson
  process of points on the $\Omega$.

\item A distance metric $D(\cdot, \cdot)$ on the space $\Omega$. One
  way to think of this is we are drawing ``lines'', i.e., geodesics,
  in some space $\Sigma$ in which $\Omega$ is embedded. The most
  common case is that the space $\Sigma = \R^n$, and the distance
  metric is simple Euclidean distance. In this case, the geodesics are
  simple lines -- hence the name of the problem. However, there are
  other possibilities.

\end{itemize}
We describe these problems by the triple: $\big(\Omega, \mu, D(\cdot,
\cdot)\big)$. However, the common cases are so common that we ommit
mentioning that the measure is uniform, or that the distance metric is
Given that the typical case of $\mu$ is uniform, and of $d$ is
Euclidean, we ommit these from the problem statement when we use these
simple defaults.

Figure~\ref{fig:eg} presents three examples: the disk-line-picking
problem, the circle-line-picking problem and the cube-line-picking
problem.

\begin{figure}[tbp]
% Figures generated with ../Matlab/Examples/LinePicking_eg.m
  \begin{center}
    \subfloat[\label{fig:disk_eg}Disk-line-picking.]%
          {\includegraphics[width=0.33\columnwidth]{../Matlab/Plots/LinePicking_eg_disk.eps}}
    \subfloat[\label{fig:circle_eg}Circle-line-picking.]%
          {\includegraphics[width=0.33\columnwidth]{../Matlab/Plots/LinePicking_eg_circle.eps}}
    \subfloat[\label{fig:cube_eg}Cube-line-picking.]%
          {\includegraphics[width=0.33\columnwidth]{../Matlab/Plots/LinePicking_eg_cube.eps}}
    \caption{Example line-picking problems.\label{fig:eg}}
  \end{center} 
\vspace{-4mm}
\end{figure}


\section{General Properties}
\label{sec:general}

\begin{enumerate}

\item Most of the cases are defined over finite regions, and hence the
  PDFs have finite support.

\item All of the distributions are {\em proper}

\item Almost all are defined on continuous, convex sets, and in this
  case the distributions are continuous, i.e., the CDF is a continuous
  function.

\item Almost all are defined on continuous, convex sets, and in this
  case the PDFs are also continuous functions.

\end{enumerate}

\subsection{Region Transforms}
\label{sec:scaling}

Many of the standard problems use a uniform point distribution and
Euclidean distances on some convex region of $R^n$. In these cases,
there is are easy scaling and trasnlation laws that means once we know
the distribution for some size region, we can compute it for any size.

Translation is trivial. Given the uniform distribution of point,
translation has no affect on the line-length distribution.

Scaling is almost as simple: if the region $\Omega$ is scaled in all
dimensions by $L$, then the problem is identical under a scaling of
the distance metric by $L$. We can therefore scale the density
functions as follows
\begin{equation}
   g_L(t) = \frac{1}{L} g_1 \left( \frac{t}{L} \right). 
\end{equation}
Non-uniform scaling is not so simple as we shall see in the results
below.

Scaling for CDFs is even simpler, we simply take
\begin{equation}
   G_L(t) = G_1 \left( \frac{t}{L} \right). 
\end{equation}


\section{Cartesian products of spaces}

One of the aspects of the line-picking problem that doesn't seem
generally considered is how to derive results for constructed
space. Perhaps the simplest example of which is the Cartesian product
of two spaces.

The Cartesian product is defined by
\begin{equation}
 S \times T = \{ (s,t) | s \in S, t \in T \}. 
\end{equation}
For instance, the square, which is the Cartesian product of two lines
segments, has been as extensively considered as any line-picking
problem, but this basic constructivist approach is not used, except
implicitly. 

The useful feature of the Cartesian product is that if we take two
independent random variables $X \in S$ and $Y \in T$, each uniformly
distributed over their respective spaces, then the random varible
$(X,Y)$ will be uniformly distributed over the space $S \times T$. As
a result, we easily can construct uniformly distributed points from
these component spaces. 

The reason it is interesting is because we can construct many common
example from Cartesian products. It also helps us to extend the notion
of the line-picking problem to spaces with alternative metrics, and
even combined metrics. For instance, assume we have distance metric
$d_S$ on $S$ and $d_T$ on $T$, we can form a new distance metric on $S
\times T$ by taking
\begin{equation}
  d_{S \times T}\Big( (X_1,Y_1), (X_2,Y_2)  \Big)
 = \left\{ \begin{array}{ll}
      \sqrt{ d_S(X_1,X_2)^2 +  d_T(Y_1,Y_2)^2}, \\
      | d_S(X_1,X_2) +  d_T(Y_1,Y_2)|, \\
      \max\{ d_S(X_1,X_2) +  d_T(Y_1,Y_2) \}, \\
    \end{array}
  \right.
\end{equation}
for the Euclidean, $\ell_1$ and $\ell_{\infty}$ distances,
respectively (though note that there is no real requirement that the
distances $d_S$ and $d_T$ match, or that they match the combining
operation, in order to create a valid metric. Moreover, there are some
interesting cases where they don't match.

Given we know the distribution of the distances on $S$ and $T$, we
should therefore be able to construct statistics for the distance
distribution on the product space, without deriving this from first
principles. We do so below for each of these cases. However, the order
in which we derive information (e.g., PDFs, CDFs, moments, etc.) may
vary depending on the metric, so we consider each below separately. 

\subsection{The Euclidean metric}

The classic Euclidean distance metric is actually one of the hardest
to work with, but there are several useful results.

The even moments $2k$ expand into a binomial, and we can exploit this
to derive formulae for the moments in terms of the moments of the
component spaces. For instance, given distances $X$ and $Y$ in each
space, then $X^2$ and $Y^2$ are independent random variables, and so
\begin{eqnarray}
  E\left[ \left( \sqrt{ X^2 + Y^2} \right)^{2k} \right] 
   & = & \sum_{i=0}^{k} \dbinom{k}{i} E[X^{2i}] E[Y^{2(n-i)}].
\end{eqnarray}



% In general we can compute 
% However, the odd moments are more difficult. 
% \begin{eqnarray}
%   E\left[ \left( \sqrt{ X^2 + Y^2} \right)^{2n+1} \right] 
%    & = &  \sum_{k=0}^{\infty}  \dbinom{(2n+1)/2}{k} E[X^{2k}] E[Y^{2n+1-2k}].
% \end{eqnarray}
% -- but  this may not work because of convergence?



We can also derive useful relationships for the PDF in the same
way. As above, it is  to work with squared distances, which will have
PDFs 
\begin{eqnarray}
  \label{eq:h_g}
  h_{X^2}(u) & = & g_X(\sqrt{u})/(2\sqrt{u}), \\
  h_{Y^2}(u) & = & g_Y(\sqrt{u})/(2\sqrt{u}), \\
\end{eqnarray}
The PDF for the sum of independent random variables is
obtained by taking the convolution of their PDFs, and we can see that
the squared distances add here, so
\begin{eqnarray}
  \label{eq:add_euclidean}
  h_{X^2+y^2}(u) & = & \int_{-\infty}^\infty h_{X^2}(s)  h_{Y^2}(u-s) \, ds
\end{eqnarray}
This convolution can then be computed directly, or by taking Laplace
tranforms (and noting that this results in a product in the Laplace
domain).  The chief difficulty in computing this convolution is often
simply that the support for most of the PDFs considered here is
finite, and therefore, the integral often breaks into different
pieces.

We can then transform back to obtain the PDF of the actual distances
by noting that
\begin{equation}
  \label{eq:g_h}
  g_{\sqrt{X^2+Y^2}}(t) 
     =  2 t \, h_{X^2+y^2}(t^2).
\end{equation}

If it is easier to compute this directly, then it may be easier to
compute moments by integrating the PDF, rather than integrating
variables directly, or using other techniques describe above.


\subsection{Manhattan distance}

In the case of the Manhattan distance, i.e., where we combine
submetrics using the sub of their absolute values, we can note that
the submetrics are guaranteed to be non-negative, and hence we are
simply adding independent random variables. Hence computing the
moments is almost trivial, i.e., 
\begin{eqnarray}
  E\left[ \left( X + Y \right)^{k} \right] 
   & = & \sum_{i=0}^{k} \dbinom{k}{i} E[X^{i}] E[Y^{(n-i)}].
\end{eqnarray}
The cross-terms of the second central moment cancel, and so the mean
and variance are simply the sum of the mean and variance of the
relevant submoments.

We can construct the PDF using convolutions as above, though without
the transforms between squared variables and back, or we could
construct them (at least numerically) by using the above moment
construction, and then inverting the moment generating function:

....


\subsection{Max metric}

When working with the maxx-metric, there is no simple relationship
between moments of the Cartesian product and its components. However,
the CDF is almost trivial to construct, as it is simply given by
\begin{equation}
  \label{eq:cdf_construction}
  G_{\max\{X,Y\}}(t)
    = \mbox{Prob}\{ \max\{X,Y\} \leq t \}
    = \mbox{Prob}\{ X \leq t \mbox{ and } Y \leq t \}
    = \mbox{Prob}\{ X \leq t \} \times \mbox{Prob}\{ Y \leq t \}
    = G_X(t) G_Y(t). 
\end{equation}


For the Max distance, there is no simple relationship, but the
simplicity of computing the PDF and CDF mean that computing the
moments is often not hard.



\section{Examples}
\label{sec:known}

We go through a list of examples, some from the literature, and some
derived here, though derivations are typically delayed until the
appendices in order to make the flow easy.

\begin{figure}[htbp]
  \begin{center}
% Figures generated with ../Matlab/Examples/LinePicking_plot.m
    \includegraphics[width=0.5\columnwidth]{../Matlab/Plots/LinePicking_plot_fix_area.eps}

    \label{fig:various}
    \caption{Example distance densities for shapes with area fixed to 1.}
  \end{center} 
\vspace{-4mm}
\end{figure}


\clearpage
\input{line.tex}

\clearpage
\input{square.tex}

\clearpage
\input{rectangle.tex}

\clearpage
\input{rect_manhattan.tex}

\clearpage
\input{rect_max.tex}

\clearpage
\input{grid.tex}

\clearpage
\input{rect_other.tex}

\clearpage
\input{cube.tex}
\clearpage
\input{hypercubemax.tex}


\clearpage
\input{hyperball}

\clearpage
\input{nsphere}

\clearpage
\input{nsphere_geodesic}

\clearpage
\input{prism_geodesic}

\clearpage
\input{cylinder_surface}

\clearpage
\input{non_uniform}

\clearpage
\subsection{Others}

Cylinder

Cylinder geodesic

Cube-face-to-face

Rectangle to Rectangle

Helix -- geodesic is obvious but Euclidean could be interesting, and
maybe a relevance to DNA
 

Lp norm -- e.g., generalize rectangle (sphere might be hard because
$cos^p+sin^p=1$ only works for p=2?)



\clearpage
\subsection{Summary}
SUMMARY TABLE -- at least giving equation and page references.

\begin{table}[ht]
  \centering
  \begin{tabular}{r|lllllllllll}
    Problem & Parameters & Mean & Variance & PDF & CDF \\
    \hline
    AUTOGENERATE
  \end{tabular}
  \caption{Summary of the examples considered here.}
  \label{tab:summary}
\end{table}

\clearpage
\input{approximation}

\clearpage
\input{numerical}

\clearpage
\input{programs}

\clearpage
\input{correlations}

 
\clearpage
\section{Conclusion and Future Work}


limit n large for various spherical cases

  -- approach Gaussian, distances are farish apart

  -- use to model distances between images

If distances are all similar as they seem to be, then Waxman
approaches ER graph 

\appendix 

\clearpage
\input{useful}
 

\setlength{\parskip}{1mm}
\bibliographystyle{ieeetr}
% \bibliography{queueing_theory,books,ip_traffic,time_series,reliability,tcp,ospf,lrd,worms,internet,routing,bgp,topology,network,traffic_engineering,algorithms,optimization,history,graph}
\bibliography{LinePicking}

\end{document}


